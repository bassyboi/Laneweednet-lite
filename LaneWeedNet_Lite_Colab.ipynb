{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "colab": {
   "name": "LaneWeedNet_Lite_Colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaneWeedNet\u2011Lite \u2014 Colab demo notebook\n",
    "Quick smoke\u2011test for training & inference on 4 equal lanes.\n",
    "\n",
    "**Repo:** https://github.com/bassyboi/Laneweednet-lite\n",
    "\n",
    "What this does:\n",
    "1. Check GPU\n",
    "2. Clone repo & install requirements\n",
    "3. (Optional) Mount Google Drive\n",
    "4. Prepare data (COCO \u279c lane labels)\n",
    "5. Train a tiny run (epochs=5 by default)\n",
    "6. Inference on a single image + batch of images\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 1) Check GPU\n",
    "import torch, platform\n",
    "print('Python:', platform.python_version())\n",
    "print('Torch:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('\u26a0\ufe0f Using CPU. Training will be slower.')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 2) Clone repo & install requirements\n",
    "%cd /content\n",
    "!rm -rf Laneweednet-lite\n",
    "!git clone https://github.com/bassyboi/Laneweednet-lite\n",
    "%cd /content/Laneweednet-lite\n",
    "\n",
    "# Colab already has torch; avoid downgrades. If requirements.txt pins torch, you can allow it.\n",
    "!pip install -r requirements.txt --quiet\n",
    "\n",
    "print('Setup complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 3) (Optional) Mount Google Drive\n",
    "use_drive = False  #@param {type:\"boolean\"}\n",
    "if use_drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print('Drive mounted at /content/drive')\n",
    "else:\n",
    "    print('Skipping Drive mount.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Prepare data\n",
    "You have two paths:\n",
    "\n",
    "**A. Already have lane label JSONs** `lanes_train.json` and `lanes_val.json` (with 4-lane targets)? Place them in `/content/Laneweednet-lite` or any folder and update paths below.\n",
    "\n",
    "**B. Start from COCO (boxes) \u279c convert to lane labels:** Provide your COCO train/val JSONs and image folder, then run the converter cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 4B) Convert COCO \u279c lane labels (one-off)\n",
    "COCO_TRAIN_JSON = '/content/data/train.json'  #@param {type:\"string\"}\n",
    "COCO_VAL_JSON   = '/content/data/val.json'    #@param {type:\"string\"}\n",
    "IMG_DIR         = '/content/data/images'      #@param {type:\"string\"}\n",
    "IMG_SIZE        = 384                         #@param {type:\"integer\"}\n",
    "LANES           = 4                           #@param {type:\"integer\"}\n",
    "AREA_THRESH     = 4800                        #@param {type:\"integer\"}\n",
    "OUT_TRAIN       = '/content/Laneweednet-lite/lanes_train.json'  #@param {type:\"string\"}\n",
    "OUT_VAL         = '/content/Laneweednet-lite/lanes_val.json'    #@param {type:\"string\"}\n",
    "\n",
    "%cd /content/Laneweednet-lite\n",
    "print('Converting TRAIN\u2026')\n",
    "!python lane_labels_from_coco.py \\\n",
    "  --coco \"$COCO_TRAIN_JSON\" \\\n",
    "  --img_dir \"$IMG_DIR\" \\\n",
    "  --img_size $IMG_SIZE \\\n",
    "  --lanes $LANES \\\n",
    "  --area_thresh $AREA_THRESH \\\n",
    "  --out \"$OUT_TRAIN\"\n",
    "\n",
    "print('Converting VAL\u2026')\n",
    "!python lane_labels_from_coco.py \\\n",
    "  --coco \"$COCO_VAL_JSON\" \\\n",
    "  --img_dir \"$IMG_DIR\" \\\n",
    "  --img_size $IMG_SIZE \\\n",
    "  --lanes $LANES \\\n",
    "  --area_thresh $AREA_THRESH \\\n",
    "  --out \"$OUT_VAL\"\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 5) Train \u2014 fast sanity run\n",
    "TRAIN_JSON = '/content/Laneweednet-lite/lanes_train.json'  #@param {type:\"string\"}\n",
    "VAL_JSON   = '/content/Laneweednet-lite/lanes_val.json'    #@param {type:\"string\"}\n",
    "IMG_DIR    = '/content/data/images'                        #@param {type:\"string\"}\n",
    "IMG_SIZE   = 384                                           #@param {type:\"integer\"}\n",
    "EPOCHS     = 5                                             #@param {type:\"integer\"}\n",
    "\n",
    "%cd /content/Laneweednet-lite\n",
    "!python train_lanes.py \\\n",
    "  --train \"$TRAIN_JSON\" \\\n",
    "  --val \"$VAL_JSON\" \\\n",
    "  --img_dir \"$IMG_DIR\" \\\n",
    "  --img $IMG_SIZE \\\n",
    "  --epochs $EPOCHS\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 6) Inference \u2014 single image\n",
    "WEIGHTS = 'runs/best.pt'                 #@param {type:\"string\"}\n",
    "TEST_IMAGE = '/content/data/test.jpg'    #@param {type:\"string\"}\n",
    "IMG_SIZE = 384                           #@param {type:\"integer\"}\n",
    "%cd /content/Laneweednet-lite\n",
    "!python infer_lanes.py \\\n",
    "  --weights \"$WEIGHTS\" \\\n",
    "  --image \"$TEST_IMAGE\" \\\n",
    "  --img $IMG_SIZE\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form"
   },
   "source": [
    "#@title 7) Inference \u2014 folder (prints lane probs per image)\n",
    "WEIGHTS = 'runs/best.pt'                      #@param {type:\"string\"}\n",
    "FOLDER  = '/content/data/frames'              #@param {type:\"string\"}\n",
    "IMG_SIZE= 384                                 #@param {type:\"integer\"}\n",
    "%cd /content/Laneweednet-lite\n",
    "import glob, os, json, subprocess\n",
    "imgs = sorted(glob.glob(os.path.join(FOLDER, '*.jpg')) + \n",
    "              glob.glob(os.path.join(FOLDER, '*.png')))\n",
    "print('Found', len(imgs), 'images')\n",
    "for i, img in enumerate(imgs[:50]):\n",
    "    print(f'[{i+1}/{len(imgs)}] {os.path.basename(img)}')\n",
    "    cmd = [\n",
    "        'python', 'infer_lanes.py',\n",
    "        '--weights', WEIGHTS,\n",
    "        '--image', img,\n",
    "        '--img', str(IMG_SIZE)\n",
    "    ]\n",
    "    subprocess.run(cmd, check=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- If you see `CUDA not available`, your Colab runtime likely lacks a GPU. Switch to *Runtime \u2192 Change runtime type \u2192 GPU*.\n",
    "- If lane labels come out skewed (too many 1s or 0s), adjust `AREA_THRESH` in the converter cell.\n",
    "- For on\u2011rig triggering, smooth the four probabilities with a small EMA + hysteresis.\n"
   ]
  }
 ]
}